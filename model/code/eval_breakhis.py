"""
Evaluation script for BreaKHis 400X and IDC external dataset.

This script assumes:
  - A trained checkpoint exists (resnet18_best.pth)
  - A training log CSV exists (training_log.csv) generated by train_breakhis.py

It performs:
  2-1: Evaluation on BreaKHis test set
       - Training & validation curves (from CSV)
       - ROC curve
       - Confusion matrix
       - Classification report (image)
  2-2: Training-time performance plots
       - Training Time per Epoch
       - Peak GPU Memory per Epoch
  2-3: Evaluation on IDC external dataset
       - ROC curve
       - Confusion matrix
       - Classification report (image)
"""

import os

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import models, transforms
from PIL import Image

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import (
    confusion_matrix,
    classification_report,
    roc_auc_score,
    roc_curve,
)
import pandas as pd


# ============================================================
# Global configuration (adjust paths if needed)
# ============================================================

BREAKHIS_ROOT = r"C:/Users/17733/Desktop/bia4/ICA/BreaKHis 400X"
IDC_EXTERNAL_TEST_DIR = r"C:/Users/17733/Desktop/bia4/ICA/IDC_external/test"

CHECKPOINT_PATH = os.path.join(BREAKHIS_ROOT, "checkpoints", "resnet18_best.pth")
TRAIN_LOG_CSV = os.path.join(BREAKHIS_ROOT, "training_log.csv")

PLOTS_DIR = os.path.join(BREAKHIS_ROOT, "plots")              # train/val curves
PERF_PLOTS_DIR = os.path.join(BREAKHIS_ROOT, "performance")   # time & GPU
INTERNAL_EVAL_DIR = os.path.join(BREAKHIS_ROOT, "internal_eval")
EXTERNAL_EVAL_DIR = os.path.join(BREAKHIS_ROOT, "external_idc")

os.makedirs(PLOTS_DIR, exist_ok=True)
os.makedirs(PERF_PLOTS_DIR, exist_ok=True)
os.makedirs(INTERNAL_EVAL_DIR, exist_ok=True)
os.makedirs(EXTERNAL_EVAL_DIR, exist_ok=True)

NUM_CLASSES = 2
BATCH_SIZE = 8

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"[INFO] Using device: {DEVICE}")

CLASS_TO_IDX = {"benign": 0, "malignant": 1}
IDX_TO_CLASS = {v: k for k, v in CLASS_TO_IDX.items()}
CLASS_NAMES = [IDX_TO_CLASS[0], IDX_TO_CLASS[1]]

MEAN = [0.755842387676239, 0.5889061689376831, 0.7419362664222717]
STD = [0.14278094470500946, 0.20091958343982697, 0.1162722110748291]


# ============================================================
# Dataset & Dataloaders (same structure as in training script)
# ============================================================

class BreastHistDataset(Dataset):
    """
    Generic binary dataset: expects two subfolders under root_dir:
      - benign
      - malignant
    """

    def __init__(self, root_dir: str, transform=None):
        super().__init__()
        self.root_dir = root_dir
        self.transform = transform

        self.samples = []
        for class_name, label in CLASS_TO_IDX.items():
            class_path = os.path.join(root_dir, class_name)
            if not os.path.isdir(class_path):
                continue
            for fname in os.listdir(class_path):
                if fname.lower().endswith((".png", ".jpg", ".jpeg", ".tif", ".tiff")):
                    self.samples.append(
                        (os.path.join(class_path, fname), label)
                    )

        print(f"[INFO] Loaded {len(self.samples)} images from {root_dir}")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        img = Image.open(img_path).convert("RGB")
        if self.transform is not None:
            img = self.transform(img)
        return img, label


test_transform = transforms.Compose([
    transforms.Resize((700, 460)),
    transforms.ToTensor(),
    transforms.Normalize(mean=MEAN, std=STD),
])


def build_breakhis_test_loader(root: str, batch_size: int = 16):
    test_dir = os.path.join(root, "test")
    test_set = BreastHistDataset(test_dir, transform=test_transform)
    test_loader = DataLoader(
        test_set,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0,
        pin_memory=True,
    )
    return test_loader


def build_idc_external_loader(test_dir: str, batch_size: int = 16):
    test_set = BreastHistDataset(test_dir, transform=test_transform)
    test_loader = DataLoader(
        test_set,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0,
        pin_memory=True,
    )
    return test_loader


# ============================================================
# Model loading
# ============================================================

def create_model(num_classes: int = 2) -> nn.Module:
    model = models.resnet18(pretrained=False)
    in_features = model.fc.in_features
    model.fc = nn.Linear(in_features, num_classes)
    return model


def load_trained_model(checkpoint_path: str, device) -> nn.Module:
    print(f"[INFO] Loading checkpoint from: {checkpoint_path}")
    model = create_model(num_classes=NUM_CLASSES)
    state_dict = torch.load(checkpoint_path, map_location=device)
    model.load_state_dict(state_dict)
    model = model.to(device)
    model.eval()
    return model


# ============================================================
# Plot helpers for 2-1 and 2-2
# ============================================================

def plot_training_curves_from_csv(csv_path: str, out_dir: str):
    if not os.path.isfile(csv_path):
        print(f"[WARN] Training log CSV not found: {csv_path}")
        return

    df = pd.read_csv(csv_path)
    epochs = df["epoch"].values

    # Loss curves
    plt.figure(figsize=(10, 6))
    plt.plot(epochs, df["train_loss"].values, label="Train Loss")
    plt.plot(epochs, df["val_loss"].values, label="Val Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title("Training and Validation Loss")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    loss_path = os.path.join(out_dir, "loss_curve.png")
    plt.savefig(loss_path, dpi=300)
    plt.close()

    # Accuracy curves
    plt.figure(figsize=(10, 6))
    plt.plot(epochs, df["train_acc"].values, label="Train Accuracy")
    plt.plot(epochs, df["val_acc"].values, label="Validation Accuracy")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.title("Training and Validation Accuracy")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    acc_path = os.path.join(out_dir, "accuracy_curve.png")
    plt.savefig(acc_path, dpi=300)
    plt.close()

    print(f"[INFO] Training curves saved to:\n  {loss_path}\n  {acc_path}")


def plot_performance_curves_from_csv(csv_path: str, out_dir: str):
    if not os.path.isfile(csv_path):
        print(f"[WARN] Training log CSV not found: {csv_path}")
        return

    df = pd.read_csv(csv_path)
    epochs = df["epoch"].values

    # Training time per epoch
    plt.figure(figsize=(10, 6))
    plt.plot(epochs, df["time_sec"].values, marker="o")
    plt.xlabel("Epoch")
    plt.ylabel("Time (seconds)")
    plt.title("Training Time per Epoch")
    plt.grid(True)
    plt.tight_layout()
    time_path = os.path.join(out_dir, "training_time_per_epoch.png")
    plt.savefig(time_path, dpi=300)
    plt.close()

    # Peak GPU memory per epoch
    plt.figure(figsize=(10, 6))
    plt.plot(epochs, df["peak_gpu_mb"].values, marker="o")
    plt.xlabel("Epoch")
    plt.ylabel("Peak GPU Memory (MB)")
    plt.title("Peak GPU Memory per Epoch")
    plt.grid(True)
    plt.tight_layout()
    mem_path = os.path.join(out_dir, "peak_gpu_memory_per_epoch.png")
    plt.savefig(mem_path, dpi=300)
    plt.close()

    print(f"[INFO] Performance curves saved to:\n  {time_path}\n  {mem_path}")


# ============================================================
# Evaluation helpers (used for both internal and external sets)
# ============================================================

def plot_confusion_matrix(cm, class_names, title: str, save_path: str):
    plt.figure(figsize=(6, 6))
    im = plt.imshow(cm, interpolation="nearest")
    plt.title(title)
    plt.colorbar(im)
    tick_marks = np.arange(len(class_names))
    plt.xticks(tick_marks, class_names, rotation=45)
    plt.yticks(tick_marks, class_names)

    thresh = cm.max() / 2.0
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            plt.text(
                j, i, str(cm[i, j]),
                horizontalalignment="center",
                color="white" if cm[i, j] > thresh else "black",
            )

    plt.ylabel("True label")
    plt.xlabel("Predicted label")
    plt.tight_layout()
    plt.savefig(save_path, dpi=300)
    plt.close()
    print(f"[INFO] Confusion matrix saved to: {save_path}")


def plot_roc_curve(y_true, y_prob, title: str, save_path: str):
    fpr, tpr, _ = roc_curve(y_true, y_prob)
    auc = roc_auc_score(y_true, y_prob)

    plt.figure(figsize=(6, 6))
    plt.plot(fpr, tpr, label=f"ROC curve (AUC = {auc:.4f})")
    plt.plot([0, 1], [0, 1], "k--", label="Random")
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title(title)
    plt.legend(loc="lower right")
    plt.tight_layout()
    plt.savefig(save_path, dpi=300)
    plt.close()
    print(f"[INFO] ROC curve saved to: {save_path}")


def save_classification_report_image(report_dict, title: str, save_path: str):
    """
    report_dict: classification_report(..., output_dict=True)
    """
    df = pd.DataFrame(report_dict).T

    plt.figure(figsize=(10, 3))
    plt.title(title, pad=20)
    plt.axis("off")

    table = plt.table(
        cellText=np.round(df.values, 2),
        rowLabels=df.index,
        colLabels=df.columns,
        cellLoc="center",
        loc="center",
    )
    table.auto_set_font_size(False)
    table.set_fontsize(8)
    table.scale(1.2, 1.2)

    plt.tight_layout()
    plt.savefig(save_path, dpi=300)
    plt.close()
    print(f"[INFO] Classification report image saved to: {save_path}")


@torch.no_grad()
def evaluate_model_full(model, dataloader, device, class_names):
    model.eval()
    all_labels = []
    all_preds = []
    all_probs = []  # probability of class "malignant" (index 1)

    for imgs, labels in dataloader:
        imgs = imgs.to(device)
        labels = labels.to(device)

        outputs = model(imgs)
        probs = F.softmax(outputs, dim=1)

        preds = torch.argmax(probs, dim=1)

        all_labels.extend(labels.cpu().numpy())
        all_preds.extend(preds.cpu().numpy())
        all_probs.extend(probs[:, 1].cpu().numpy())

    all_labels = np.array(all_labels)
    all_preds = np.array(all_preds)
    all_probs = np.array(all_probs)

    acc = (all_labels == all_preds).mean()
    cm = confusion_matrix(all_labels, all_preds)

    report_text = classification_report(
        all_labels, all_preds, target_names=class_names, digits=4
    )
    report_dict = classification_report(
        all_labels, all_preds, target_names=class_names, output_dict=True
    )

    try:
        auc = roc_auc_score(all_labels, all_probs)
    except ValueError:
        auc = None

    return acc, cm, report_text, report_dict, all_labels, all_probs, auc


def evaluate_and_plot(
    model,
    dataloader,
    device,
    class_names,
    out_dir: str,
    prefix: str,
    title_prefix: str,
):
    os.makedirs(out_dir, exist_ok=True)

    acc, cm, report_text, report_dict, y_true, y_prob, auc = evaluate_model_full(
        model, dataloader, device, class_names
    )

    print("\n========== Evaluation Result ==========")
    print(f"Dataset: {title_prefix}")
    print(f"Accuracy: {acc:.4f}")
    if auc is not None:
        print(f"AUC (malignant=positive): {auc:.4f}")
    print("\nClassification report:")
    print(report_text)
    print("\nConfusion matrix:")
    print(cm)

    cm_path = os.path.join(out_dir, f"{prefix}_confusion_matrix.png")
    roc_path = os.path.join(out_dir, f"{prefix}_roc_curve.png")
    cr_path = os.path.join(out_dir, f"{prefix}_classification_report.png")

    plot_confusion_matrix(
        cm,
        class_names,
        title=f"Confusion Matrix - {title_prefix}",
        save_path=cm_path,
    )

    if auc is not None:
        plot_roc_curve(
            y_true,
            y_prob,
            title=f"ROC Curve - {title_prefix}",
            save_path=roc_path,
        )

    save_classification_report_image(
        report_dict,
        title=f"Classification Report - {title_prefix}",
        save_path=cr_path,
    )


# ============================================================
# Main
# ============================================================

def main():
    # 2-1: draw train/val curves from CSV
    plot_training_curves_from_csv(TRAIN_LOG_CSV, out_dir=PLOTS_DIR)

    # 2-2: draw performance curves (time, GPU memory)
    plot_performance_curves_from_csv(TRAIN_LOG_CSV, out_dir=PERF_PLOTS_DIR)

    # Load trained model
    model = load_trained_model(CHECKPOINT_PATH, DEVICE)

    # 2-1: evaluation on BreaKHis test set
    test_loader = build_breakhis_test_loader(BREAKHIS_ROOT, batch_size=BATCH_SIZE)
    evaluate_and_plot(
        model=model,
        dataloader=test_loader,
        device=DEVICE,
        class_names=CLASS_NAMES,
        out_dir=INTERNAL_EVAL_DIR,
        prefix="breakhis",
        title_prefix="BreaKHis Test",
    )

    # 2-3: evaluation on IDC external dataset (if available)
    if os.path.isdir(IDC_EXTERNAL_TEST_DIR):
        idc_loader = build_idc_external_loader(IDC_EXTERNAL_TEST_DIR, batch_size=BATCH_SIZE)
        evaluate_and_plot(
            model=model,
            dataloader=idc_loader,
            device=DEVICE,
            class_names=CLASS_NAMES,
            out_dir=EXTERNAL_EVAL_DIR,
            prefix="idc_external",
            title_prefix="IDC External Test",
        )
    else:
        print(
            f"[WARN] IDC_EXTERNAL_TEST_DIR does not exist: {IDC_EXTERNAL_TEST_DIR}\n"
            f"Skip 2-3 external evaluation."
        )


if __name__ == "__main__":
    main()
